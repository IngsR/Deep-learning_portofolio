{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process A train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "# Your parameters\n",
    "sr = 16000  # Sample rate\n",
    "snr = 8     # Signal-to-noise ratio\n",
    "n_mels = 128      # Number of Mel filterbanks\n",
    "hop_length = 256  # Hop length for STFT\n",
    "n_fft = 512      # FFT size for STFT\n",
    "save_path = \"/content/Dataset\"\n",
    "mix_path = os.path.join(save_path, \"mixtures\")\n",
    "sim_path = os.path.join(save_path, \"sources\")\n",
    "target_length_train = sr * 5  # 5 seconds = 80,000 samples for training\n",
    "target_length_valid = 81408   # Max length for 160 frames at hop_length=512 (5.088s)\n",
    "\n",
    "# Paths to MS-SNSD dataset\n",
    "clean_train_path = \"/content/MS-SNSD/clean_train\"\n",
    "noise_train_path = \"/content/MS-SNSD/noise_train\"\n",
    "clean_valid_path = \"/content/MS-SNSD/clean_test\"\n",
    "noise_valid_path = \"/content/MS-SNSD/noise_test\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(mix_path, exist_ok=True)\n",
    "os.makedirs(sim_path, exist_ok=True)\n",
    "\n",
    "# Add Noise Function\n",
    "def add_noise(clean, noise, snr):\n",
    "    clean_power = np.mean(clean**2)\n",
    "    noise_power = np.mean(noise**2)\n",
    "    desired_noise_power = clean_power / (10**(snr / 10))\n",
    "    noise = noise * np.sqrt(desired_noise_power / (noise_power + 1e-8))\n",
    "    return clean + noise\n",
    "\n",
    "# Pre-generate mixture and source files\n",
    "def prepare_data(clean_path, noise_path, output_mix_path, output_sim_path, num_files=6000, is_training=True):\n",
    "    clean_files = [f for f in os.listdir(clean_path) if f.endswith(\".wav\")]\n",
    "    noise_files = [f for f in os.listdir(noise_path) if f.endswith(\".wav\")]\n",
    "    speaker_list = []\n",
    "    processed_files = 0\n",
    "\n",
    "    random.shuffle(clean_files)\n",
    "\n",
    "    for i, cfile in enumerate(clean_files):\n",
    "        if processed_files >= num_files:\n",
    "            break\n",
    "\n",
    "        clean, _ = librosa.load(os.path.join(clean_path, cfile), sr=sr, mono=True)\n",
    "        noise_file = random.choice(noise_files)\n",
    "        noise, _ = librosa.load(os.path.join(noise_path, noise_file), sr=sr, mono=True)\n",
    "\n",
    "        if is_training:\n",
    "            if len(clean) < target_length_train:\n",
    "                continue\n",
    "            clean = clean[:target_length_train]\n",
    "            noise = noise[:target_length_train]\n",
    "        else:\n",
    "            min_len = min(len(clean), len(noise))\n",
    "            max_len = min(min_len, target_length_valid)\n",
    "            clean = clean[:max_len]\n",
    "            noise = noise[:max_len]\n",
    "\n",
    "        noisy = add_noise(clean, noise, snr)\n",
    "\n",
    "        speaker_id = f\"spk_{processed_files:04d}\"\n",
    "        sf.write(os.path.join(output_mix_path, f\"mix_{speaker_id}.wav\"), noisy, sr)\n",
    "        os.makedirs(os.path.join(output_sim_path, speaker_id), exist_ok=True)\n",
    "        sf.write(os.path.join(output_sim_path, speaker_id, \"s1.wav\"), clean, sr)\n",
    "        speaker_list.append(speaker_id)\n",
    "\n",
    "        processed_files += 1\n",
    "        if processed_files % 1000 == 0:\n",
    "            print(f\"Processed {processed_files} files\")\n",
    "\n",
    "    print(f\"Total files processed: {processed_files}\")\n",
    "    return speaker_list\n",
    "\n",
    "# Prepare data\n",
    "print(\"Preparing training data (5 seconds only)...\")\n",
    "train_speakers = prepare_data(clean_train_path, noise_train_path, mix_path, sim_path, is_training=True)\n",
    "print(\"Preparing validation data (max 5.088s)...\")\n",
    "valid_speakers = prepare_data(clean_valid_path, noise_valid_path, mix_path, sim_path, num_files=1000, is_training=False)\n",
    "\n",
    "# Modified train_gen and valid_gen to enforce max_frames\n",
    "def train_gen():\n",
    "    max_frames = 160  # Hardcode to match pipeline\n",
    "    for speaker in train_speakers:\n",
    "        mixture, sr_local = librosa.load(mix_path + 'mix_' + speaker + '.wav', sr=sr, mono=False)\n",
    "        mixture_ft = librosa.stft(mixture, n_fft=512, hop_length=512, win_length=512)  # Align hop_length\n",
    "        mixture_mel = librosa.feature.melspectrogram(S=np.abs(mixture_ft), sr=sr_local, n_fft=512, hop_length=512, win_length=None, window='hann')\n",
    "        # Truncate to max_frames\n",
    "        mixture_mel = mixture_mel[:, :max_frames]\n",
    "\n",
    "        output_masks = []\n",
    "        for ii in np.arange(1, 2):\n",
    "            sim, sr_local = librosa.load(sim_path + speaker + '/s' + str(ii) + '.wav', sr=sr, mono=False)\n",
    "            sim_ft = librosa.stft(sim, n_fft=512, hop_length=512, win_length=512)\n",
    "            sim_mel = librosa.feature.melspectrogram(S=np.abs(sim_ft), sr=sr_local, n_fft=512, hop_length=512, win_length=None, window='hann')\n",
    "            sim_mel = sim_mel[:, :max_frames]  # Truncate to match\n",
    "            source_mask = np.abs(sim_mel) / (np.maximum(sim_mel, mixture_mel) + 1e-8)\n",
    "            output_masks.append(source_mask)\n",
    "        output_masks = np.stack(output_masks, axis=-1)\n",
    "\n",
    "        input_data = tf.convert_to_tensor(mixture_mel, dtype=tf.float32)\n",
    "        source_mask = tf.convert_to_tensor(output_masks, dtype=tf.float32)\n",
    "\n",
    "        yield input_data, source_mask\n",
    "\n",
    "def valid_gen():\n",
    "    max_frames = 160  # Hardcode to match pipeline\n",
    "    for speaker in valid_speakers:\n",
    "        mixture, sr_local = librosa.load(mix_path + 'mix_' + speaker + '.wav', sr=sr, mono=False)\n",
    "        mixture_ft = librosa.stft(mixture, n_fft=512, hop_length=512, win_length=512)\n",
    "        mixture_mel = librosa.feature.melspectrogram(S=np.abs(mixture_ft), sr=sr_local, n_fft=512, hop_length=512, win_length=None, window='hann')\n",
    "        mixture_mel = mixture_mel[:, :max_frames]  # Truncate to max_frames\n",
    "\n",
    "        output_masks = []\n",
    "        for ii in np.arange(1, 2):\n",
    "            sim, sr_local = librosa.load(sim_path + speaker + '/s' + str(ii) + '.wav', sr=sr, mono=False)\n",
    "            sim_ft = librosa.stft(sim, n_fft=512, hop_length=512, win_length=512)\n",
    "            sim_mel = librosa.feature.melspectrogram(S=np.abs(sim_ft), sr=sr_local, n_fft=512, hop_length=512, win_length=None, window='hann')\n",
    "            sim_mel = sim_mel[:, :max_frames]  # Truncate to match\n",
    "            source_mask = np.abs(sim_mel) / (np.maximum(sim_mel, mixture_mel) + 1e-8)\n",
    "            output_masks.append(source_mask)\n",
    "        output_masks = np.stack(output_masks, axis=-1)\n",
    "\n",
    "        input_data = tf.convert_to_tensor(mixture_mel, dtype=tf.float32)\n",
    "        source_mask = tf.convert_to_tensor(output_masks, dtype=tf.float32)\n",
    "\n",
    "        yield input_data, source_mask\n",
    "\n",
    "# U-Net Model\n",
    "def build_unet(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
    "    bottleneck = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    up4 = layers.UpSampling2D((2, 2))(bottleneck)\n",
    "    concat4 = layers.Concatenate()([up4, conv3])\n",
    "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat4)\n",
    "    up5 = layers.UpSampling2D((2, 2))(conv4)\n",
    "    concat5 = layers.Concatenate()([up5, conv2])\n",
    "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat5)\n",
    "    up6 = layers.UpSampling2D((2, 2))(conv5)\n",
    "    concat6 = layers.Concatenate()([up6, conv1])\n",
    "    conv6 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(concat6)\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv6)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Fix path syntax\n",
    "    mix_path = mix_path + \"/\"\n",
    "    sim_path = sim_path + \"/\"\n",
    "\n",
    "    # Set max_frames\n",
    "    max_frames = 160  # Matches 5s training and truncated validation\n",
    "    input_shape = (n_mels, max_frames, 1)\n",
    "    batch_size = 16\n",
    "\n",
    "    # Output signature\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(n_mels, max_frames), dtype=tf.float32),  # Fixed size\n",
    "        tf.TensorSpec(shape=(n_mels, max_frames, 1), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    # Data pipeline\n",
    "    ds_train = tf.data.Dataset.from_generator(\n",
    "        train_gen,\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(buffer_size=1024)\n",
    "    ds_train = ds_train.batch(batch_size)  # No padding needed, fixed size\n",
    "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.repeat(1)\n",
    "\n",
    "    ds_valid = tf.data.Dataset.from_generator(\n",
    "        valid_gen,\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    ds_valid = ds_valid.batch(batch_size)  # No padding needed, fixed size\n",
    "    ds_valid = ds_valid.prefetch(tf.data.AUTOTUNE)\n",
    "    ds_valid = ds_valid.repeat(1)\n",
    "\n",
    "    # Ensure checkpoint directory exists\n",
    "    os.makedirs('model_checkpoints', exist_ok=True)\n",
    "\n",
    "    # Clear previous models\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Initialize model\n",
    "    model_unet = build_unet(input_shape)\n",
    "    model_unet.summary()\n",
    "\n",
    "    # Training configuration\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    initial_learning_rate = 0.003\n",
    "\n",
    "    def lr_schedule(epoch, lr):\n",
    "        if epoch % 10 == 0 and epoch != 0:\n",
    "            return lr * 0.5\n",
    "        return lr\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='model_checkpoints/model_unet_epoch_{epoch:02d}.weights.h5',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "    model_unet.compile(optimizer=optimizer, loss=loss_fn, metrics=['mae'])\n",
    "\n",
    "    # Train\n",
    "    history = model_unet.fit(ds_train, epochs=150, callbacks=[callback_lr, checkpoint_callback], validation_data=ds_valid)\n",
    "\n",
    "    # Save final model\n",
    "    model_unet.save('model_unet_final.keras')\n",
    "\n",
    "    # Plot training history\n",
    "    plt.plot(history.history['loss'], label='Learning loss f-value')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss f-statement')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss F-account')\n",
    "    plt.title('Change in the training and validation loss f-ratio over epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Your parameters\n",
    "sr = 16000\n",
    "snr = 8\n",
    "n_mels = 128\n",
    "hop_length = 256\n",
    "n_fft = 512\n",
    "save_path = \"/content/Dataset\"\n",
    "mix_path = os.path.join(save_path, \"mixtures\")\n",
    "sim_path = os.path.join(save_path, \"sources\")\n",
    "target_length_train = sr * 5\n",
    "max_frames = 160\n",
    "\n",
    "# Paths to MS-SNSD dataset\n",
    "clean_train_path = \"/content/MS-SNSD/clean_train\"\n",
    "noise_train_path = \"/content/MS-SNSD/noise_train\"\n",
    "clean_valid_path = \"/content/MS-SNSD/clean_test\"\n",
    "noise_valid_path = \"/content/MS-SNSD/noise_test\"\n",
    "\n",
    "# Add Noise Function\n",
    "def add_noise(clean, noise, snr):\n",
    "    clean_power = np.mean(clean**2)\n",
    "    noise_power = np.mean(noise**2)\n",
    "    desired_noise_power = clean_power / (10**(snr / 10))\n",
    "    noise = noise * np.sqrt(desired_noise_power / (noise_power + 1e-8))\n",
    "    return clean + noise\n",
    "\n",
    "# Prepare test data\n",
    "def prepare_test_data(clean_path, noise_path, output_mix_path, output_sim_path, num_files=1):\n",
    "    clean_files = [f for f in os.listdir(clean_path) if f.endswith(\".wav\")]\n",
    "    noise_files = [f for f in os.listdir(noise_path) if f.endswith(\".wav\")]\n",
    "    test_speakers = []\n",
    "    processed_files = 0\n",
    "\n",
    "    random.shuffle(clean_files)\n",
    "\n",
    "    for i, cfile in enumerate(clean_files):\n",
    "        if processed_files >= num_files:\n",
    "            break\n",
    "\n",
    "        clean, _ = librosa.load(os.path.join(clean_path, cfile), sr=sr, mono=True)\n",
    "        noise_file = random.choice(noise_files)\n",
    "        noise, _ = librosa.load(os.path.join(noise_path, noise_file), sr=sr, mono=True)\n",
    "\n",
    "        if len(clean) < target_length_train:\n",
    "            continue\n",
    "        clean = clean[:target_length_train]\n",
    "        noise = noise[:target_length_train]\n",
    "\n",
    "        noisy = add_noise(clean, noise, snr)\n",
    "\n",
    "        speaker_id = f\"test_spk_{processed_files:04d}\"\n",
    "        sf.write(os.path.join(output_mix_path, f\"mix_{speaker_id}.wav\"), noisy, sr)\n",
    "        os.makedirs(os.path.join(output_sim_path, speaker_id), exist_ok=True)\n",
    "        sf.write(os.path.join(output_sim_path, speaker_id, \"s1.wav\"), clean, sr)\n",
    "        test_speakers.append(speaker_id)\n",
    "\n",
    "        processed_files += 1\n",
    "\n",
    "    print(f\"Test files processed: {processed_files}\")\n",
    "    return test_speakers\n",
    "\n",
    "# Process test input with padding and phase preservation\n",
    "def process_test_input(mix_file, sim_file):\n",
    "    mixture, _ = librosa.load(mix_file, sr=sr, mono=False)\n",
    "    sim, _ = librosa.load(sim_file, sr=sr, mono=False)\n",
    "\n",
    "    # Compute STFT and save phase\n",
    "    mixture_ft = librosa.stft(mixture, n_fft=n_fft, hop_length=512, win_length=512)\n",
    "    mixture_mel = librosa.feature.melspectrogram(S=np.abs(mixture_ft), sr=sr, n_fft=512, hop_length=512, win_length=None, window='hann')\n",
    "    mixture_phase = np.angle(mixture_ft)  # Save phase\n",
    "    if mixture_mel.shape[1] < max_frames:\n",
    "        pad_width = max_frames - mixture_mel.shape[1]\n",
    "        mixture_mel = np.pad(mixture_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        # Pad phase to match max_frames (though STFT might already be truncated)\n",
    "        mixture_phase = mixture_phase[:, :max_frames]\n",
    "    mixture_mel = mixture_mel[:, :max_frames]\n",
    "\n",
    "    sim_ft = librosa.stft(sim, n_fft=512, hop_length=512, win_length=512)\n",
    "    sim_mel = librosa.feature.melspectrogram(S=np.abs(sim_ft), sr=sr, n_fft=512, hop_length=512, win_length=None, window='hann')\n",
    "    if sim_mel.shape[1] < max_frames:\n",
    "        pad_width = max_frames - sim_mel.shape[1]\n",
    "        sim_mel = np.pad(sim_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    sim_mel = sim_mel[:, :max_frames]\n",
    "\n",
    "    input_data = tf.convert_to_tensor(mixture_mel, dtype=tf.float32)[tf.newaxis, ..., tf.newaxis]\n",
    "    ground_truth_mask = np.abs(sim_mel) / (np.maximum(sim_mel, mixture_mel) + 1e-8)\n",
    "\n",
    "    return input_data, mixture_ft, mixture_phase, ground_truth_mask\n",
    "\n",
    "# Reconstruct audio from predicted mask using saved phase\n",
    "def reconstruct_audio(mixture_ft, predicted_mask, mixture_phase, hop_length=512, win_length=512):\n",
    "    mixture_magnitude = np.abs(mixture_ft)  # Shape: (257, 157)\n",
    "    n_frames = mixture_magnitude.shape[1]\n",
    "\n",
    "    # Interpolate mask to STFT frequency bins\n",
    "    mel_basis = librosa.filters.mel(sr=sr, n_fft=512, n_mels=n_mels)\n",
    "    inverse_mel = np.linalg.pinv(mel_basis)\n",
    "    predicted_mask_stft = np.dot(inverse_mel, predicted_mask)  # (257, 160)\n",
    "    predicted_mask_stft = predicted_mask_stft[:, :n_frames]  # (257, 157)\n",
    "\n",
    "    # Smooth and apply adjustable threshold\n",
    "    predicted_mask_stft = gaussian_filter(predicted_mask_stft, sigma=1)\n",
    "    predicted_mask_stft = np.clip(predicted_mask_stft, 0, 1)\n",
    "    predicted_mask_stft = (predicted_mask_stft > 0.3).astype(float)  # Softer threshold\n",
    "\n",
    "    # Apply mask and debug\n",
    "    predicted_magnitude = mixture_magnitude * predicted_mask_stft\n",
    "    print(\"Predicted Mask STFT Min/Max:\", predicted_mask_stft.min(), predicted_mask_stft.max())\n",
    "    print(\"Predicted Magnitude Min/Max:\", predicted_magnitude.min(), predicted_magnitude.max())\n",
    "\n",
    "    # Reconstruct using saved phase\n",
    "    predicted_stft = predicted_magnitude * np.exp(1j * mixture_phase)\n",
    "    audio = librosa.istft(predicted_stft, hop_length=hop_length, win_length=win_length)\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    return audio\n",
    "\n",
    "# Signal-to-Distortion Ratio (SDR) calculation\n",
    "def calculate_sdr(reference, estimation):\n",
    "    min_length = min(len(reference), len(estimation))\n",
    "    reference = reference[:min_length]\n",
    "    estimation = estimation[:min_length]\n",
    "    signal_power = np.sum(reference ** 2)\n",
    "    error = reference - estimation\n",
    "    error_power = np.sum(error ** 2)\n",
    "    sdr = 10 * np.log10(signal_power / (error_power + 1e-8))\n",
    "    return sdr\n",
    "\n",
    "# Load the trained model\n",
    "model_unet = tf.keras.models.load_model('model_unet_final.keras')\n",
    "\n",
    "# Prepare test data\n",
    "print(\"Preparing test data...\")\n",
    "test_speakers = prepare_test_data(clean_valid_path, noise_valid_path, mix_path, sim_path, num_files=1)\n",
    "test_speaker = test_speakers[0]\n",
    "mix_file = os.path.join(mix_path, f\"mix_{test_speaker}.wav\")\n",
    "sim_file = os.path.join(sim_path, test_speaker, \"s1.wav\")\n",
    "\n",
    "# Process test input\n",
    "input_data, mixture_ft, mixture_phase, ground_truth_mask = process_test_input(mix_file, sim_file)\n",
    "\n",
    "# Predict the mask\n",
    "predicted_mask = model_unet.predict(input_data)[0, :, :, 0]\n",
    "\n",
    "# Reconstruct the separated audio\n",
    "separated_audio = reconstruct_audio(mixture_ft, predicted_mask, mixture_phase)\n",
    "\n",
    "# Save the separated audio\n",
    "output_audio_file = os.path.join(save_path, f\"separated_{test_speaker}.wav\")\n",
    "sf.write(output_audio_file, separated_audio, sr)\n",
    "print(f\"Separated audio saved to: {output_audio_file}\")\n",
    "\n",
    "# Load original mixture and ground truth for comparison\n",
    "mixture_audio, _ = librosa.load(mix_file, sr=sr, mono=True)\n",
    "ground_truth_audio, _ = librosa.load(sim_file, sr=sr, mono=True)\n",
    "\n",
    "# Compute separation quality\n",
    "separated_mel = librosa.feature.melspectrogram(y=separated_audio, sr=sr, n_fft=512, hop_length=512, n_mels=n_mels)\n",
    "if separated_mel.shape[1] < max_frames:\n",
    "    pad_width = max_frames - separated_mel.shape[1]\n",
    "    separated_mel = np.pad(separated_mel, ((0, 0), (0, pad_width)), mode='constant')\n",
    "separated_mel = separated_mel[:, :max_frames]\n",
    "mse = mean_squared_error(ground_truth_mask, separated_mel)\n",
    "print(f\"MSE between Ground Truth and Separated Mel Spectrograms: {mse:.4f}\")\n",
    "\n",
    "sdr = calculate_sdr(ground_truth_audio, separated_audio)\n",
    "print(f\"Signal-to-Distortion Ratio (SDR): {sdr:.2f} dB\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.title(\"Mixture Mel Spectrogram\")\n",
    "plt.imshow(input_data[0, :, :, 0], aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Mel Bins\")\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.imshow(predicted_mask, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Mel Bins\")\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.imshow(ground_truth_mask, aspect='auto', origin='lower', cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Mel Bins\")\n",
    "\n",
    "separated_mel_vis = input_data[0, :, :, 0] * predicted_mask\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.title(\"Separated Mel Spectrogram\")\n",
    "plt.imshow(separated_mel_vis, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Mel Bins\")\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.title(\"Waveforms\")\n",
    "plt.plot(mixture_audio[:target_length_train], label=\"Mixture\", alpha=0.5)\n",
    "plt.plot(ground_truth_audio[:target_length_train], label=\"Ground Truth\", alpha=0.5)\n",
    "plt.plot(separated_audio, label=\"Separated\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Play audio in Colab\n",
    "print(\"Playing Mixture Audio:\")\n",
    "display(Audio(mixture_audio, rate=sr))\n",
    "print(\"Playing Ground Truth Audio:\")\n",
    "display(Audio(ground_truth_audio, rate=sr))\n",
    "print(\"Playing Separated Audio:\")\n",
    "display(Audio(separated_audio, rate=sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
